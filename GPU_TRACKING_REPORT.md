# GPUè¿½è¸ªæŠ¥å‘Šï¼šgpu_id=2 çš„ä½¿ç”¨æƒ…å†µ

## ğŸ“‹ æ¦‚è¿°
è¿½è¸ª `gpu_id=2` åœ¨é¢„è®­ç»ƒå’Œä¸»è®­ç»ƒä¸¤ä¸ªé˜¶æ®µä¸­çš„å®Œæ•´ä¼ é€’å’Œä½¿ç”¨é€»è¾‘ã€‚

---

## ğŸ”„ ç¬¬ä¸€é˜¶æ®µï¼šé¢„è®­ç»ƒï¼ˆcond_model_main.py â†’ iTransformerï¼‰

### 1ï¸âƒ£ **å‚æ•°ä¼ é€’**
```bash
# scripts/point forecasting/iTransformer/ettm2.sh ç¬¬50è¡Œ
gpu_id=2

# ç¬¬93è¡Œä¼ é€’ç»™ cond_model_main.py
--gpu $gpu_id  # å®é™…å€¼ï¼š--gpu 2
```

### 2ï¸âƒ£ **å‚æ•°è§£æ**
```python
# cond_model_main.py ç¬¬111è¡Œ
parser.add_argument('--gpu', type=int, default=0, help='gpu')

# ç¬¬115è¡Œ
args = parser.parse_args()  # args.gpu = 2
```

### 3ï¸âƒ£ **è®¾å¤‡åˆå§‹åŒ–**
```python
# models/exp/exp_basic_point.py ç¬¬23-32è¡Œ
def _acquire_device(self):
    if self.args.use_gpu:
        # å…³é”®æ­¥éª¤1: è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œé™åˆ¶å¯è§GPUä¸ºç‰©ç†GPU 2
        os.environ["CUDA_VISIBLE_DEVICES"] = str(self.args.gpu)  # "2"
        
        # å…³é”®æ­¥éª¤2: åˆ›å»ºé€»è¾‘è®¾å¤‡ cuda:0 (æ˜ å°„åˆ°ç‰©ç†GPU 2)
        device = torch.device('cuda:0')
        
        print('Use GPU: cuda:{}'.format(self.args.gpu))  # æ‰“å°: Use GPU: cuda:2
    return device

# ç¬¬16è¡Œ: æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡
self.model = self._build_model().to(self.device)  # æ¨¡å‹åœ¨ç‰©ç†GPU 2ä¸Š
```

**ğŸ”‘ å…³é”®æœºåˆ¶ï¼šCUDA_VISIBLE_DEVICES**
- `os.environ["CUDA_VISIBLE_DEVICES"] = "2"` ä½¿å¾—ç¨‹åºåªèƒ½çœ‹åˆ°ç‰©ç†GPU 2
- PyTorchä¸­çš„ `cuda:0` è¢«æ˜ å°„åˆ°ç‰©ç†GPU 2
- è¿™æ˜¯ä¸€ç§æ ‡å‡†çš„GPUéš”ç¦»æŠ€æœ¯

### 4ï¸âƒ£ **è®­ç»ƒé˜¶æ®µæ•°æ®ä¼ è¾“**
```python
# models/exp/exp_long_term_forecasting_point.py ç¬¬129-136è¡Œ
for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):
    batch_x = batch_x.float().to(self.device)        # âœ… ç§»åŠ¨åˆ°GPU 2
    batch_y = batch_y.float().to(self.device)        # âœ… ç§»åŠ¨åˆ°GPU 2
    batch_x_mark = batch_x_mark.float().to(self.device)  # âœ… ç§»åŠ¨åˆ°GPU 2
    batch_y_mark = batch_y_mark.float().to(self.device)  # âœ… ç§»åŠ¨åˆ°GPU 2
    dec_inp = torch.cat([...]).float().to(self.device)   # âœ… ç§»åŠ¨åˆ°GPU 2
```

### 5ï¸âƒ£ **éªŒè¯é˜¶æ®µæ•°æ®ä¼ è¾“**
```python
# models/exp/exp_long_term_forecasting_point.py ç¬¬56-80è¡Œ
def vali(self, vali_data, vali_loader, criterion):
    for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):
        batch_x = batch_x.float().to(self.device)        # âœ… ç§»åŠ¨åˆ°GPU 2
        batch_x_mark = batch_x_mark.float().to(self.device)  # âœ… ç§»åŠ¨åˆ°GPU 2
        batch_y_mark = batch_y_mark.float().to(self.device)  # âœ… ç§»åŠ¨åˆ°GPU 2
        dec_inp = torch.cat([...]).float().to(self.device)   # âœ… ç§»åŠ¨åˆ°GPU 2
        batch_y = batch_y[:, -self.args.pred_len:, :].to(self.device)  # âœ… ç§»åŠ¨åˆ°GPU 2
```

### 6ï¸âƒ£ **æµ‹è¯•é˜¶æ®µæ•°æ®ä¼ è¾“**
```python
# models/exp/exp_long_term_forecasting_point.py ç¬¬220-228è¡Œ
def test(self, setting, test=0, save_result=False, plot=False):
    # ç¬¬206è¡Œ: æ¨¡å‹ç¡®ä¿åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
    self.model.to(self.device)  # âœ… æ¨¡å‹åœ¨GPU 2ä¸Š
    
    for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):
        batch_x = batch_x.float().to(self.device)        # âœ… ç§»åŠ¨åˆ°GPU 2
        batch_y = batch_y.float().to(self.device)        # âœ… ç§»åŠ¨åˆ°GPU 2
        batch_x_mark = batch_x_mark.float().to(self.device)  # âœ… ç§»åŠ¨åˆ°GPU 2
        batch_y_mark = batch_y_mark.float().to(self.device)  # âœ… ç§»åŠ¨åˆ°GPU 2
```

**âœ… é¢„è®­ç»ƒé˜¶æ®µç»“è®ºï¼šæ‰€æœ‰æ“ä½œï¼ˆè®­ç»ƒã€éªŒè¯ã€æµ‹è¯•ï¼‰éƒ½æ­£ç¡®ä½¿ç”¨GPU 2**

---

## ğŸ”„ ç¬¬äºŒé˜¶æ®µï¼šä¸»è®­ç»ƒï¼ˆmain.py â†’ æ‰©æ•£æ¨¡å‹ï¼‰

### 1ï¸âƒ£ **å‚æ•°ä¼ é€’**
```bash
# scripts/point forecasting/iTransformer/ettm2.sh ç¬¬148è¡Œ
--gpu $gpu_id  # å®é™…å€¼ï¼š--gpu 2
```

### 2ï¸âƒ£ **å‚æ•°è§£æ**
```python
# utils/params_init.py (ç”±main.pyè°ƒç”¨)
parser.add_argument('--gpu', type=int, default=1, help='gpu')
args = params_init.get_args()  # args.gpu = 2
```

### 3ï¸âƒ£ **GPUè®¾å¤‡è®¾ç½®**
```python
# main.py ç¬¬25-33è¡Œ
args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False
if args.use_gpu:
    if args.use_multi_gpu:
        # å¤šGPUæ¨¡å¼
        args.devices = args.devices.replace(' ', '')
        device_ids = args.devices.split(',')
        args.device_ids = [int(id_) for id_ in device_ids]
        args.gpu = args.device_ids[0]
    else:
        # å•GPUæ¨¡å¼ï¼šç›´æ¥è®¾ç½®å½“å‰è®¾å¤‡ä¸ºGPU 2
        torch.cuda.set_device(args.gpu)  # âœ… è®¾ç½®ä¸ºGPU 2
```

### 4ï¸âƒ£ **è®¾å¤‡åˆå§‹åŒ–**
```python
# models/exp/exp_basic.py ç¬¬24-37è¡Œ
def _acquire_device(self):
    if torch.cuda.is_available():
        if self.args.use_gpu:
            # å…³é”®æ­¥éª¤1: è®¾ç½®ç¯å¢ƒå˜é‡
            os.environ["CUDA_VISIBLE_DEVICES"] = str(self.args.gpu)  # "2"
            
            # å…³é”®æ­¥éª¤2: åˆ›å»ºé€»è¾‘è®¾å¤‡
            device = torch.device('cuda:0')  # æ˜ å°„åˆ°ç‰©ç†GPU 2
            
            print('Use GPU: cuda:{}'.format(self.args.gpu))  # æ‰“å°: Use GPU: cuda:2
    return device

# ç¬¬16-17è¡Œ: æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡
self.model = model.to(self.device)  # æ‰©æ•£æ¨¡å‹åœ¨GPU 2ä¸Š
self.cond_pred_model = cond_pred_model.to(self.device)  # iTransformeråœ¨GPU 2ä¸Š
```

### 5ï¸âƒ£ **è®­ç»ƒé˜¶æ®µæ•°æ®ä¼ è¾“**
```python
# models/exp/exp_main.py ç¬¬246-262è¡Œ
for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):
    batch_x = batch_x.float().to(self.device)        # âœ… ç§»åŠ¨åˆ°GPU 2
    batch_y = batch_y.float().to(self.device)        # âœ… ç§»åŠ¨åˆ°GPU 2
    batch_x_mark = batch_x_mark.float().to(self.device)  # âœ… ç§»åŠ¨åˆ°GPU 2
    batch_y_mark = batch_y_mark.float().to(self.device)  # âœ… ç§»åŠ¨åˆ°GPU 2
    dec_inp = torch.cat([...]).float().to(self.device)   # âœ… ç§»åŠ¨åˆ°GPU 2
    
    # æ—¶é—´æ­¥ä¹Ÿåœ¨GPU 2ä¸Š
    t = torch.randint(low=0, high=self.model.num_timesteps, size=(n // 2 + 1,)).to(self.device)
    t = torch.cat([t, self.model.num_timesteps - 1 - t], dim=0)[:n].to(self.device)
```

### 6ï¸âƒ£ **éªŒè¯å’Œæµ‹è¯•é˜¶æ®µ**
```python
# models/exp/exp_main.py æµ‹è¯•æ–¹æ³•ä¸­
for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):
    batch_x = batch_x.float().to(self.device)        # âœ… ç§»åŠ¨åˆ°GPU 2
    batch_y = batch_y.float().to(self.device)        # âœ… ç§»åŠ¨åˆ°GPU 2
    # ... æ‰€æœ‰æ•°æ®éƒ½ç§»åŠ¨åˆ°self.device (GPU 2)
```

**âœ… ä¸»è®­ç»ƒé˜¶æ®µç»“è®ºï¼šæ‰€æœ‰æ“ä½œï¼ˆè®­ç»ƒã€éªŒè¯ã€æµ‹è¯•ï¼‰éƒ½æ­£ç¡®ä½¿ç”¨GPU 2**

---

## ğŸ¯ æ€»ç»“

### âœ… **ç¡®è®¤ï¼šGPU 2 è¢«æ­£ç¡®ä½¿ç”¨**

| é˜¶æ®µ | è®­ç»ƒ | éªŒè¯ | æµ‹è¯• | è®¾å¤‡è®¾ç½®æ–¹å¼ |
|------|------|------|------|-------------|
| **é¢„è®­ç»ƒï¼ˆiTransformerï¼‰** | âœ… GPU 2 | âœ… GPU 2 | âœ… GPU 2 | `CUDA_VISIBLE_DEVICES="2"` + `cuda:0` |
| **ä¸»è®­ç»ƒï¼ˆæ‰©æ•£æ¨¡å‹ï¼‰** | âœ… GPU 2 | âœ… GPU 2 | âœ… GPU 2 | `torch.cuda.set_device(2)` + `CUDA_VISIBLE_DEVICES="2"` + `cuda:0` |

### ğŸ”‘ **å…³é”®æœºåˆ¶**

1. **ç¯å¢ƒå˜é‡éš”ç¦»**ï¼š
   ```python
   os.environ["CUDA_VISIBLE_DEVICES"] = "2"
   ```
   - é™åˆ¶ç¨‹åºåªèƒ½çœ‹åˆ°ç‰©ç†GPU 2
   - æä¾›GPUèµ„æºéš”ç¦»

2. **è®¾å¤‡æ˜ å°„**ï¼š
   ```python
   device = torch.device('cuda:0')  # é€»è¾‘GPU 0 â†’ ç‰©ç†GPU 2
   ```
   - åœ¨ç¨‹åºå†…éƒ¨ä½¿ç”¨ `cuda:0`
   - å®é™…è¿è¡Œåœ¨ç‰©ç†GPU 2ä¸Š

3. **æ˜¾å¼è®¾å¤‡è®¾ç½®ï¼ˆä»…ä¸»è®­ç»ƒï¼‰**ï¼š
   ```python
   torch.cuda.set_device(2)  # ç›´æ¥è®¾ç½®å½“å‰CUDAè®¾å¤‡
   ```

### ğŸ“Š **æ•°æ®æµè¿½è¸ª**

```
è„šæœ¬å‚æ•° (gpu_id=2)
    â†“
å‘½ä»¤è¡Œå‚æ•° (--gpu 2)
    â†“
args.gpu = 2
    â†“
CUDA_VISIBLE_DEVICES="2" + torch.cuda.set_device(2)
    â†“
self.device = torch.device('cuda:0') [æ˜ å°„åˆ°ç‰©ç†GPU 2]
    â†“
æ¨¡å‹: .to(self.device)
    â†“
æ•°æ®: batch_x.to(self.device), batch_y.to(self.device), ...
    â†“
âœ… æ‰€æœ‰è®¡ç®—åœ¨ç‰©ç†GPU 2ä¸Šæ‰§è¡Œ
```

### âš¡ **éªŒè¯æ–¹æ³•**

å¯ä»¥åœ¨è¿è¡Œæ—¶ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤éªŒè¯GPUä½¿ç”¨æƒ…å†µï¼š

```bash
# å®æ—¶ç›‘æ§GPU 2çš„ä½¿ç”¨æƒ…å†µ
watch -n 1 nvidia-smi

# æˆ–è€…åªæŸ¥çœ‹GPU 2
nvidia-smi -i 2

# åœ¨è®­ç»ƒå¼€å§‹åï¼Œåº”è¯¥çœ‹åˆ°GPU 2çš„æ˜¾å­˜å ç”¨å’Œåˆ©ç”¨ç‡ä¸Šå‡
```

### ğŸ‰ **æœ€ç»ˆç»“è®º**

**æ˜¯çš„ï¼åœ¨é¢„è®­ç»ƒå’Œä¸»è®­ç»ƒçš„æ‰€æœ‰é˜¶æ®µï¼ˆè®­ç»ƒã€éªŒè¯ã€æµ‹è¯•ï¼‰ä¸­ï¼Œéƒ½æ­£ç¡®ä½¿ç”¨äº†GPU 2è¿›è¡Œè®¡ç®—ã€‚**

æ•´ä¸ªæµç¨‹é€šè¿‡ï¼š
1. ç¯å¢ƒå˜é‡ `CUDA_VISIBLE_DEVICES`
2. è®¾å¤‡å¯¹è±¡ `self.device = torch.device('cuda:0')`
3. æ•°æ®å’Œæ¨¡å‹çš„ `.to(self.device)` è°ƒç”¨

ç¡®ä¿äº†æ‰€æœ‰å¼ é‡æ“ä½œéƒ½åœ¨æŒ‡å®šçš„GPU 2ä¸Šæ‰§è¡Œã€‚

